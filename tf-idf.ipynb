{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922cb5a3-3d87-422f-b9c0-0852848a12f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 14:37:17.291933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-06 14:37:17.291967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182a654b-baf9-4687-bb30-6016b378c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = fetch_20newsgroups(categories=['sci.space'], \n",
    "                            remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e791b1b-8ab6-45c6-9431-164aa2fdd01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc49dec7-84f4-4e31-9f81-5dfc4598a62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64094241-8827-4b34-ab49-2ee68c18acb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nAny lunar satellite needs fuel to do regular orbit corrections, and when\\nits fuel runs out it will crash within months.  The orbits of the Apollo\\nmotherships changed noticeably during lunar missions lasting only a few\\ndays.  It is *possible* that there are stable orbits here and there --\\nthe Moon's gravitational field is poorly mapped -- but we know of none.\\n\\nPerturbations from Sun and Earth are relatively minor issues at low\\naltitudes.  The big problem is that the Moon's own gravitational field\\nis quite lumpy due to the irregular distribution of mass within the Moon.\",\n",
       " '\\nGlad to see Griffin is spending his time on engineering rather than on\\nritual purification of the language.  Pity he got stuck with the turkey\\nrather than one of the sensible options.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e844515-9077-4878-91ac-6b87fe28a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like before, if we want to use spaCy's tokenizer, we need \n",
    "# to create a callback. Remember to upgrade spaCy if you need \n",
    "# to (refer to beginnning of file for commentary and instructions).\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# We don't need named-entity recognition nor dependency parsing for\n",
    "# this so these components are disabled. This will speed up the \n",
    "# pipeline. We do need part-of-speech tagging however.\n",
    "unwanted_pipes = [\"ner\", \"parser\"]\n",
    "\n",
    "# For this exercise, we'll remove punctuation and spaces (which\n",
    "# includes newlines), filter for tokens consisting of alphabetic\n",
    "# characters, and return the lemma (which require POS tagging).\n",
    "def spacy_tokenizer(doc):\n",
    "  with nlp.disable_pipes(*unwanted_pipes):\n",
    "    return [t.lemma_ for t in nlp(doc) if \\\n",
    "            not t.is_punct and \\\n",
    "            not t.is_space and \\\n",
    "            t.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f5bca2-3cab-4105-b27e-ca9789c8752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 218 ms, total: 14.1 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the default settings of TfidfVectorizer.\n",
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
    "features = vectorizer.fit_transform(corpus.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c87a95-0834-4826-9c24-a7b59119dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9469\n"
     ]
    }
   ],
   "source": [
    "# The number of unique tokens.\n",
    "print(len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75dd488-3854-4321-a8b9-c8322bb0f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 9469)\n"
     ]
    }
   ],
   "source": [
    "# The dimensions of our feature matrix. X rows (documents) by Y columns (tokens).\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dd6b79-7f54-49a8-ac1b-534485b3ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5076)\t0.10452465319204224\n",
      "  (0, 2355)\t0.12746673572641337\n",
      "  (0, 4351)\t0.15331277268825122\n",
      "  (0, 2464)\t0.10862134983649849\n",
      "  (0, 4927)\t0.17102243214182047\n",
      "  (0, 6721)\t0.09939758959196421\n",
      "  (0, 5997)\t0.10183273017124134\n",
      "  (0, 6531)\t0.08455248650428543\n",
      "  (0, 903)\t0.08929749232550656\n",
      "  (0, 321)\t0.11094564582599897\n",
      "  (0, 4907)\t0.0824741348739743\n",
      "  (0, 637)\t0.05104326044583604\n",
      "  (0, 4378)\t0.10269890253976902\n",
      "  (0, 5285)\t0.13259379932649137\n",
      "  (0, 6928)\t0.12524362655380208\n",
      "  (0, 2501)\t0.07376358403679217\n",
      "  (0, 8137)\t0.09512941822420008\n",
      "  (0, 3299)\t0.051873252060803496\n",
      "  (0, 6196)\t0.13901479196044814\n",
      "  (0, 5662)\t0.11219221685212125\n",
      "  (0, 4604)\t0.06321553828701997\n",
      "  (0, 9188)\t0.060883075560077576\n",
      "  (0, 1148)\t0.048917557559216875\n",
      "  (0, 5035)\t0.12319856435864923\n",
      "  (0, 6371)\t0.15331277268825122\n",
      "  :\t:\n",
      "  (0, 1351)\t0.09036221462758656\n",
      "  (0, 5413)\t0.17102243214182047\n",
      "  (0, 456)\t0.10452465319204224\n",
      "  (0, 5802)\t0.09913077191467295\n",
      "  (0, 8399)\t0.20402427950185778\n",
      "  (0, 5387)\t0.10099496207230896\n",
      "  (0, 9318)\t0.19294889310170182\n",
      "  (0, 1905)\t0.135603113234682\n",
      "  (0, 9281)\t0.05987440623617899\n",
      "  (0, 4382)\t0.07654678460464726\n",
      "  (0, 5953)\t0.06436834906895003\n",
      "  (0, 7238)\t0.09789423612431815\n",
      "  (0, 4391)\t0.0752239608115977\n",
      "  (0, 9244)\t0.07158783287193733\n",
      "  (0, 377)\t0.10543917645771247\n",
      "  (0, 1850)\t0.135603113234682\n",
      "  (0, 5895)\t0.21554964821105232\n",
      "  (0, 6906)\t0.135603113234682\n",
      "  (0, 2377)\t0.043431930668155455\n",
      "  (0, 8522)\t0.06551367047806549\n",
      "  (0, 3312)\t0.19879517918392842\n",
      "  (0, 5555)\t0.07462975640531987\n",
      "  (0, 7306)\t0.08827537051327851\n",
      "  (0, 4929)\t0.17756264093912102\n",
      "  (0, 431)\t0.07006958599794154\n"
     ]
    }
   ],
   "source": [
    "# What the encoding of the first document looks like in sparse format.\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc35889-8571-4f7a-9f8a-eeec7e6db040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the query into a TF-IDF vector.\n",
    "query = [\"lunar orbit\"]\n",
    "query_tfidf = vectorizer.transform(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8936c9-18dc-4967-9deb-17bd2a4e746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarities between the query and each document.\n",
    "# We're calling flatten() here becaue cosine_similarity returns a list\n",
    "# of lists and we just want a single list.\n",
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab47bf9-cc61-412d-9d11-4af749e44e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy's argsort() method returns a list of *indices* that\n",
    "# would sort an array:\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "#\n",
    "# The sort is ascending, but we want the largest k cosine_similarites\n",
    "# at the bottom of the sort. So we negate k, and get the last k\n",
    "# entries of the indices list in reverse order. There are faster\n",
    "# ways to do this using things like argpartition but this is\n",
    "# more succinct.\n",
    "def top_k(arr, k):\n",
    "  kth_largest = (k + 1) * -1\n",
    "  return np.argsort(arr)[:kth_largest:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8659942e-a013-4e7f-bb27-927cf7c6d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249 108   0 312 509]\n"
     ]
    }
   ],
   "source": [
    "# So for our query above, these are the top five documents.\n",
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "print(top_related_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a98df5c1-0a16-451c-bdb4-ff9a8cfdec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4784239  0.42898437 0.27362524 0.19484222 0.19133134]\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at their respective cosine similarities.\n",
    "print(cosine_similarities[top_related_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa43984c-9ec7-434d-8f98-7d866cdb722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actually, Hiten wasn't originally intended to go into lunar orbit at all,\n",
      "so it indeed didn't have much fuel on hand.  The lunar-orbit mission was\n",
      "an afterthought, after Hagoromo (a tiny subsatellite deployed by Hiten\n",
      "during a lunar flyby) had a transmitter failure and its proper insertion\n",
      "into lunar orbit couldn't be positively confirmed.\n",
      "\n",
      "It should be noted that the technique does have disadvantages.  It takes\n",
      "a long time, and you end up with a relatively inconvenient lunar orbit.\n",
      "If you want something useful like a low circular polar orbit, you do have\n",
      "to plan to expend a certain amount of fuel, although it is reduced from\n",
      "what you'd need for the brute-force approach.\n"
     ]
    }
   ],
   "source": [
    "# Top match.\n",
    "print(corpus.data[top_related_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e31c93-d516-4c7a-a1b0-5eb04c1ceca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Their Hiten engineering-test mission spent a while in a highly eccentric\n",
      "Earth orbit doing lunar flybys, and then was inserted into lunar orbit\n",
      "using some very tricky gravity-assist-like maneuvering.  This meant that\n",
      "it would crash on the Moon eventually, since there is no such thing as\n",
      "a stable lunar orbit (as far as anyone knows), and I believe I recall\n",
      "hearing recently that it was about to happen.\n"
     ]
    }
   ],
   "source": [
    "# Second-best match.\n",
    "print(corpus.data[top_related_indices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b585c5a-c710-45b8-909a-875fc8863ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[388 546 250   1 517]\n",
      "[0.44078811 0.33651546 0.26761732 0.23992367 0.06274624]\n"
     ]
    }
   ],
   "source": [
    "# Try a different query\n",
    "query = [\"griffin\"]\n",
    "query_tfidf = vectorizer.transform(query)\n",
    "\n",
    "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n",
    "top_related_indices = top_k(cosine_similarities, 5)\n",
    "\n",
    "print(top_related_indices)\n",
    "print(cosine_similarities[top_related_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e317978b-e5ca-49ac-b7af-e4f063f48da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "First I've heard of it. Offhand:\n",
      "\n",
      "Griffin is no longer an \"office\" head, so that's bad.\n",
      "\n",
      "On the other hand:\n",
      "\n",
      "Regress seemed to think: we can't fund anything by Griffin, because\n",
      "that would mean (and we have the lies by the old hardliners about the\n",
      "$ 400 billion mars mission to prove it) that we would be buying into a\n",
      "mission to Mars that would cost 400 billion. Therefore there will be\n",
      "no Artemis or 20 million dollar lunar orbiter et cetera...\n",
      "\n",
      "They were killing Griffin's main program simply because some sycophants\n",
      "somewhere had Congress beleivin that to do so would simply be to buy into\n",
      "the same old stuff. Sorta like not giving aid to Yeltsin because he's\n",
      "a communist hardliner.\n",
      "\n",
      "At least now the sort of reforms Griffin was trying to bring forward\n",
      "won't be trapped in their own little easily contained and defunded\n",
      "ghetto. That Griffin is staying in some capacity is very very very\n",
      "good. And if he brings something up, noone can say \"why don't you go\n",
      "back to the OSE where you belong\" (and where he couldn't even get money\n",
      "for design studies).\n"
     ]
    }
   ],
   "source": [
    "# for i in top_related_indices:\n",
    "#     print(corpus.data[i])\n",
    "#     print('********************')\n",
    "print(corpus.data[top_related_indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300b8ec-0b4c-4836-a7cf-ac2f26c13eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
